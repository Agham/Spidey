# Spidey
This is an open source multi-threaded website crawler written in Python to crawl all the URLs of a particular website. 

To make use of this crawler all you need to do is just run "main.py" and enter a "project name" and "URL of wbesite" in the respective order.
That's it ! Spidey will crawl the website for you. A file called "crawled.txt" will contain the final list of crawled URLs.
